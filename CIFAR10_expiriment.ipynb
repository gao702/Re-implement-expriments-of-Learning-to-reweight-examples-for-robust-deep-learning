{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "get cifar10 data"
      ],
      "metadata": {
        "id": "IBVg2TLOtlmD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjohXrNGtI5Z",
        "outputId": "d389ed71-561a-4924-a130-3670d10fbfe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opvvx6oFtVEV",
        "outputId": "4482931a-871d-410d-9664-2a028ac82cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the dataset is too big. we get a smaller one."
      ],
      "metadata": {
        "id": "7jxdlexPtkmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a smaller training set with 500 samples per class\n",
        "x_train_small = []\n",
        "y_train_small = []\n",
        "\n",
        "for i in range(10):\n",
        "  class_indices = tf.where(y_train == i)[:, 0]\n",
        "  selected_indices = tf.random.shuffle(class_indices)[:500]\n",
        "  x_train_small.append(x_train[selected_indices])\n",
        "  y_train_small.append(y_train[selected_indices])\n",
        "\n",
        "x_train_small = tf.concat(x_train_small, axis=0)\n",
        "y_train_small = tf.concat(y_train_small, axis=0)\n",
        "\n",
        "print(\"Shape of x_train_small:\", x_train_small.shape)\n",
        "print(\"Shape of y_train_small:\", y_train_small.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y6tyW4ctzuG",
        "outputId": "7b19e9da-67f8-40d0-8603-43e538a4ff02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train_small: (5000, 32, 32, 3)\n",
            "Shape of y_train_small: (5000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a smaller testing set with 500 samples per class\n",
        "x_test_small = []\n",
        "y_test_small = []\n",
        "\n",
        "for i in range(10):\n",
        "  class_indices = tf.where(y_test == i)[:, 0]\n",
        "  selected_indices = tf.random.shuffle(class_indices)[:100]\n",
        "  x_test_small.append(x_test[selected_indices])\n",
        "  y_test_small.append(y_test[selected_indices])\n",
        "\n",
        "x_test_small = tf.concat(x_test_small, axis=0)\n",
        "y_test_small = tf.concat(y_test_small, axis=0)\n",
        "\n",
        "print(\"Shape of x_test_small:\", x_test_small.shape)\n",
        "print(\"Shape of y_test_small:\", y_test_small.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av2meQMMulv9",
        "outputId": "ff9ffe50-5cfd-4bc9-a862-a209b7f002ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_test_small: (1000, 32, 32, 3)\n",
            "Shape of y_test_small: (1000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get 40% of data flipped to label 3"
      ],
      "metadata": {
        "id": "4ihzUvZdvo4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the training labels\n",
        "y_train_flipped = y_train_small.numpy().copy()\n",
        "\n",
        "# Define the percentage of labels to flip\n",
        "flip_percent = 0.4\n",
        "\n",
        "# Determine the number of labels to flip\n",
        "num_labels_to_flip = int(flip_percent * len(y_train_flipped))\n",
        "\n",
        "# Get the indices of the labels to flip\n",
        "flip_indices = np.random.choice(len(y_train_flipped), num_labels_to_flip, replace=False)\n",
        "\n",
        "# Loop over the indices to flip and set them to 3\n",
        "for idx in flip_indices:\n",
        "    y_train_flipped[idx] = 3\n",
        "    "
      ],
      "metadata": {
        "id": "iu7ztFWjvpPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "try baseline"
      ],
      "metadata": {
        "id": "yd6OkFLowthj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.Dense(128, activation='relu',use_bias=False),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "# Define the loss function\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer_SGD=tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer_SGD, loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "T=100\n",
        "for t in range(T):\n",
        "  if (t!=0):\n",
        "    model.load_weights('model_weights.h5')\n",
        "  # Train the model\n",
        "  model.fit(x_train_small, y_train_small,batch_size=500)\n",
        "  model.save_weights('model_weights.h5')\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(x_test_small, y_test_small)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmLrJawgwslF",
        "outputId": "1e17b77e-6551-43e3-ee6f-1558f5b1b3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 43ms/step - loss: 2318433.0000 - accuracy: 0.1002\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 2.3015 - accuracy: 0.0978\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 2.3012 - accuracy: 0.0978\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 2.3010 - accuracy: 0.0978\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3009 - accuracy: 0.0978\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3009 - accuracy: 0.0978\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3008 - accuracy: 0.0978\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3008 - accuracy: 0.0958\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3013 - accuracy: 0.0950\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3012 - accuracy: 0.0950\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3012 - accuracy: 0.0950\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3012 - accuracy: 0.0954\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3012 - accuracy: 0.0972\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3012 - accuracy: 0.1002\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 2.3012 - accuracy: 0.1002\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 2.3012 - accuracy: 0.1002\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3012 - accuracy: 0.1004\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3011 - accuracy: 0.1004\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.3011 - accuracy: 0.1004\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3016 - accuracy: 0.1004\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3009 - accuracy: 0.1006\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3006 - accuracy: 0.1008\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3005 - accuracy: 0.1008\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3005 - accuracy: 0.1008\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3004 - accuracy: 0.1008\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3004 - accuracy: 0.1008\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3004 - accuracy: 0.1008\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3004 - accuracy: 0.1008\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3004 - accuracy: 0.1008\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.3004 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 2.3004 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 2.3004 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.3003 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 2.3003 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3003 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3003 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3003 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3003 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3003 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3003 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3002 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3002 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.3002 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.3002 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3002 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3002 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3002 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3002 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3002 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3002 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.3001 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3000 - accuracy: 0.1010\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.3000 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3007 - accuracy: 0.0992\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3005 - accuracy: 0.0990\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.3005 - accuracy: 0.0990\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 2.3005 - accuracy: 0.0990\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 2.3005 - accuracy: 0.0990\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 2.3005 - accuracy: 0.0990\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 2.3005 - accuracy: 0.0990\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3005 - accuracy: 0.0990\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3005 - accuracy: 0.0990\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3005 - accuracy: 0.0990\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.3005 - accuracy: 0.0990\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 2.3005 - accuracy: 0.0998\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3019 - accuracy: 0.0990\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3018734455108643, 0.0989999994635582]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(43)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.Dense(128, activation='relu',use_bias=False),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "# Define the loss function\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer_SGD=tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer_SGD, loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "T=100\n",
        "for t in range(T):\n",
        "  if (t!=0):\n",
        "    model.load_weights('model_weights.h5')\n",
        "  # Train the model\n",
        "  model.fit(x_train_small, y_train_flipped,batch_size=500)\n",
        "  model.save_weights('model_weights.h5')\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(x_test_small, y_test_small)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbEc-7n9z3Bd",
        "outputId": "b683a7d3-cddc-49fe-c1a2-a7bc05c89ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 805049.0625 - accuracy: 0.3000\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.2876 - accuracy: 0.4582\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.2730 - accuracy: 0.4582\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.2594 - accuracy: 0.4582\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.2462 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.2332 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.2205 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 2.2082 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.1961 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.1843 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.1728 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.1617 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.1508 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.1403 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.1300 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.1200 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.1104 - accuracy: 0.4584\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.1010 - accuracy: 0.4586\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.0919 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.0831 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.0746 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.0664 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.0584 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.0507 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.0433 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.0361 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 2.0292 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 2.0226 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 2.0162 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 2.0100 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.0041 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9984 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.9929 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9876 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.9826 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.9777 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.9731 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9686 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.9644 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.9603 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9564 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 1.9526 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9490 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9456 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.9423 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.9392 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9363 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 1.9334 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.9307 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9281 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9256 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9233 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 1.9210 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9189 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.9168 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 1.9149 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9130 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9113 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 1.9096 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 1.9080 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 1.9065 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 1.9050 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.9037 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9023 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.9011 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.8999 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 1.8988 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.8977 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.8967 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.8958 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.8949 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.8940 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 1.8932 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.8924 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.8917 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 1.8910 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.8903 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.8897 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 1.8891 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.8885 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.8879 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.8874 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.8869 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.8865 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 1.8860 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.8856 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.8852 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.8849 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.8845 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.8842 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 1.8839 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 1.8836 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 1.8833 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 1.8830 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 1.8827 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 1.8825 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.8823 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.8820 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.8818 - accuracy: 0.4588\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.8816 - accuracy: 0.4588\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.5500 - accuracy: 0.1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.55001163482666, 0.10000000149011612]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "try our method"
      ],
      "metadata": {
        "id": "ZStaWb-Q0u5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a smaller validation set with 10 samples per class\n",
        "val_indices = np.array([], dtype=np.int32)\n",
        "\n",
        "# Iterate over the classes and randomly select 10 samples for each class\n",
        "for class_idx in range(10):\n",
        "    class_indices = np.where(y_train == class_idx)[0]\n",
        "    val_class_indices = np.random.choice(class_indices, size=10, replace=False)\n",
        "    val_indices = np.concatenate([val_indices, val_class_indices])\n",
        "\n",
        "# Remove the validation samples from the training set\n",
        "x_val = x_train[val_indices]\n",
        "y_val = y_train[val_indices]\n",
        "\n",
        "print(\"Shape of x_train_small:\", x_val.shape)\n",
        "print(\"Shape of y_train_small:\", y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrcl1VMt1e3W",
        "outputId": "e9ebd839-208c-43ac-da05-648148b661dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train_small: (100, 32, 32, 3)\n",
            "Shape of y_train_small: (100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample minibatch"
      ],
      "metadata": {
        "id": "ryhcXhvo4oI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SampleMiniBatch(data, batch_size=500):\n",
        "  x_train, y_train=data\n",
        "  x_train = x_train.numpy()\n",
        "  #y_train = y_train.numpy()\n",
        "  mini_indices = np.array([], dtype=np.int32)\n",
        "\n",
        "  # Iterate over the classes and randomly select 10 samples for each class\n",
        "  for class_idx in range(10):\n",
        "    class_indices = np.where(y_train == class_idx)[0]\n",
        "    mini_class_indices = np.random.choice(class_indices, size=50, replace=False)\n",
        "    mini_indices = np.concatenate([mini_indices, mini_class_indices])\n",
        "\n",
        "  x_mini = x_train[mini_indices]\n",
        "  y_mini = y_train[mini_indices]\n",
        "  return [x_mini,y_mini]"
      ],
      "metadata": {
        "id": "7uqUZ0eo4qxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=(x_train_small,y_train_flipped)\n",
        "x_mini,y_mini=SampleMiniBatch(data)\n",
        "print(\"Shape of x_mini:\", x_mini.shape)\n",
        "print(\"Shape of y_mini:\", y_mini.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJfojKUk59a1",
        "outputId": "bd691c6c-079f-4002-fe75-1f9e55fd7aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_mini: (500, 32, 32, 3)\n",
            "Shape of y_mini: (500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(43)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(32, 32, 3),name='flatten_layer'),\n",
        "    tf.keras.layers.Dense(128, activation='relu',use_bias=False,name='dense_layer'),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "# Define the loss function\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer_SGD=tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer_SGD, loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "# Define the model temp\n",
        "# Define the model\n",
        "model_temp = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(32, 32, 3),name='flatten_layer'),\n",
        "    tf.keras.layers.Dense(128, activation='relu',use_bias=False,name='dense_layer'),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "# Define the loss function\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer_SGD=tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "# Compile the model\n",
        "model_temp.compile(optimizer=optimizer_SGD, loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "T=100\n",
        "for t in range(T):\n",
        "  print(\"t=\",t)\n",
        "  data=(x_train_small,y_train_flipped)\n",
        "  x_mini, y_mini = SampleMiniBatch(data)\n",
        "  if (t!=0):\n",
        "    model_temp.load_weights('model_weights.h5')\n",
        "  # Train the model\n",
        "  model_temp.fit(x_mini, y_mini)\n",
        "  # Create a new model that outputs the output of the desired layer\n",
        "  intermediate_layer_model = tf.keras.models.Model(inputs=model_temp.input,\n",
        "                                                 outputs=model_temp.get_layer('flatten_layer').output)\n",
        "  # Get the output of the desired layer for a given input\n",
        "  z_train = intermediate_layer_model.predict(x_mini)\n",
        "  z_validation = intermediate_layer_model.predict(x_val)\n",
        "  z_combine=tf.matmul(z_train,tf.transpose(z_validation))\n",
        "  comparison_matrix = (y_mini == tf.transpose(y_val))\n",
        "  integer_matrix = tf.cast(comparison_matrix, dtype=tf.float32)\n",
        "  weight_mat=tf.multiply(z_combine, integer_matrix)\n",
        "  weight_ours = tf.reduce_sum(weight_mat, axis=1, keepdims=True)\n",
        "  weight_ours=weight_ours/np.sum(weight_ours)\n",
        "  if (t!=0):\n",
        "    model.load_weights('model_weights.h5')\n",
        "  model.fit(x_mini, y_mini,sample_weight=weight_ours)\n",
        "  model.save_weights('model_weights.h5')\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-BVzqSL0ugn",
        "outputId": "3a65c132-d2b6-429d-fc6d-2d8cf24b620e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t= 0\n",
            "16/16 [==============================] - 3s 18ms/step - loss: 624028.0625 - accuracy: 0.0860\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 1s 10ms/step - loss: 0.3701 - accuracy: 0.1120\n",
            "t= 1\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 190805.8594 - accuracy: 0.0960\n",
            "16/16 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1452 - accuracy: 0.1460\n",
            "t= 2\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294327.5625 - accuracy: 0.1040\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.1720\n",
            "t= 3\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 339024.1250 - accuracy: 0.1020\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.1680\n",
            "t= 4\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 480186.6562 - accuracy: 0.1000\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.1540\n",
            "t= 5\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 311771.6250 - accuracy: 0.1100\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.1600\n",
            "t= 6\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118790.6562 - accuracy: 0.0920\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.1800\n",
            "t= 7\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224088.7656 - accuracy: 0.0880\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.1640\n",
            "t= 8\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86488.9531 - accuracy: 0.0960\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.1160\n",
            "t= 9\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 377451.0625 - accuracy: 0.0800\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.1260\n",
            "t= 10\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 129108.7031 - accuracy: 0.1160\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 0.1420\n",
            "t= 11\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 137167.0625 - accuracy: 0.0840\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0083 - accuracy: 0.1380\n",
            "t= 12\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 140829.3281 - accuracy: 0.1140\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.1440\n",
            "t= 13\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119694.3750 - accuracy: 0.0960\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.1440\n",
            "t= 14\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222571.2812 - accuracy: 0.0820\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.1280\n",
            "t= 15\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69333.4453 - accuracy: 0.0800\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.1200\n",
            "t= 16\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103496.2969 - accuracy: 0.1120\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.1180\n",
            "t= 17\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 201464.0938 - accuracy: 0.0820\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.1300\n",
            "t= 18\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220410.0781 - accuracy: 0.0980\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 0.1440\n",
            "t= 19\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210564.7812 - accuracy: 0.0800\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.1280\n",
            "t= 20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130093.8203 - accuracy: 0.0740\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.1280\n",
            "t= 21\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104166.8672 - accuracy: 0.1060\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.1240\n",
            "t= 22\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175058.5938 - accuracy: 0.0920\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.1160\n",
            "t= 23\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 32979.4922 - accuracy: 0.1140\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.1280\n",
            "t= 24\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243101.5469 - accuracy: 0.0760\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.1380\n",
            "t= 25\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144262.7031 - accuracy: 0.1080\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.1440\n",
            "t= 26\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 297384.5938 - accuracy: 0.0800\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.1160\n",
            "t= 27\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 52322.1719 - accuracy: 0.1000\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.1240\n",
            "t= 28\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91006.7422 - accuracy: 0.1100\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.1360\n",
            "t= 29\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198652.4531 - accuracy: 0.0820\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.1360\n",
            "t= 30\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 348113.3438 - accuracy: 0.0800\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.1240\n",
            "t= 31\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139142.6562 - accuracy: 0.0920\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.1240\n",
            "t= 32\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 52080.5234 - accuracy: 0.1200\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.1360\n",
            "t= 33\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 404810.1562 - accuracy: 0.0940\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.1180\n",
            "t= 34\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201404.5781 - accuracy: 0.0900\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.1260\n",
            "t= 35\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71184.9219 - accuracy: 0.0880\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.1200\n",
            "t= 36\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100052.6406 - accuracy: 0.0840\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.1100\n",
            "t= 37\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1736420.2500 - accuracy: 0.0700\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.1180\n",
            "t= 38\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116323.7656 - accuracy: 0.0980\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.1260\n",
            "t= 39\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 46696.2734 - accuracy: 0.1100\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.1000\n",
            "t= 40\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130728.8125 - accuracy: 0.0820\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 0.1180\n",
            "t= 41\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 71984.6016 - accuracy: 0.0760\n",
            "16/16 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 0.1140\n",
            "t= 42\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 484419.3125 - accuracy: 0.1040\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 0.1260\n",
            "t= 43\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 57525.1445 - accuracy: 0.1080\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.1280\n",
            "t= 44\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 37563.6016 - accuracy: 0.0780\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.1280\n",
            "t= 45\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181357.7969 - accuracy: 0.1020\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.1180\n",
            "t= 46\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101408.6250 - accuracy: 0.0920\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.1280\n",
            "t= 47\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81543.3359 - accuracy: 0.0820\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.1320\n",
            "t= 48\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228015.9531 - accuracy: 0.0820\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.1220\n",
            "t= 49\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 47588.4492 - accuracy: 0.0980\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.1200\n",
            "t= 50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 26531.0898 - accuracy: 0.1140\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.1340\n",
            "t= 51\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132323.3594 - accuracy: 0.0760\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.1480\n",
            "t= 52\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96914.4688 - accuracy: 0.0880\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.1140\n",
            "t= 53\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 39662.1055 - accuracy: 0.1140\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.1180\n",
            "t= 54\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184168.0938 - accuracy: 0.0760\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.1340\n",
            "t= 55\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 41513.2031 - accuracy: 0.1340\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.1260\n",
            "t= 56\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 6866.8638 - accuracy: 0.1260\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 0.1160\n",
            "t= 57\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 330719.5625 - accuracy: 0.0860\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 0.1340\n",
            "t= 58\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 315.4671 - accuracy: 0.1080\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.1140\n",
            "t= 59\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 27671.3555 - accuracy: 0.0880\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.1140\n",
            "t= 60\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84345.9922 - accuracy: 0.0880\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.1140\n",
            "t= 61\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153350.7500 - accuracy: 0.0760\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.1380\n",
            "t= 62\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 65608.4375 - accuracy: 0.1100\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.1220\n",
            "t= 63\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 48321.1250 - accuracy: 0.1060\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.1240\n",
            "t= 64\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105639.3594 - accuracy: 0.1040\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.1160\n",
            "t= 65\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1222.9492 - accuracy: 0.1320\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.1220\n",
            "t= 66\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114886.9688 - accuracy: 0.1000\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.1220\n",
            "t= 67\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 35752.6875 - accuracy: 0.0780\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.1220\n",
            "t= 68\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20247.4375 - accuracy: 0.0960\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.1200\n",
            "t= 69\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20446.8047 - accuracy: 0.0800\n",
            "16/16 [==============================] - 1s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.1180\n",
            "t= 70\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3553.3354 - accuracy: 0.1000\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 0.1120\n",
            "t= 71\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 167534.6875 - accuracy: 0.0820\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 0.1360\n",
            "t= 72\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 114724.8828 - accuracy: 0.0940\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 0.1220\n",
            "t= 73\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 27436.9668 - accuracy: 0.0860\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.1200\n",
            "t= 74\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 65403.0898 - accuracy: 0.1100\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.1160\n",
            "t= 75\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 29604.0234 - accuracy: 0.0920\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.1200\n",
            "t= 76\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 54393.5000 - accuracy: 0.0740\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.1260\n",
            "t= 77\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 103482.7891 - accuracy: 0.1060\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.1420\n",
            "t= 78\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103898.2109 - accuracy: 0.0940\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.1340\n",
            "t= 79\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169989.3594 - accuracy: 0.0960\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.1200\n",
            "t= 80\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.4277 - accuracy: 0.1360\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.1380\n",
            "t= 81\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 21966.2109 - accuracy: 0.1040\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.1300\n",
            "t= 82\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 59204.5781 - accuracy: 0.1000\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.1220\n",
            "t= 83\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 34324.6680 - accuracy: 0.0980\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.1360\n",
            "t= 84\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100853.0859 - accuracy: 0.0880\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.1320\n",
            "t= 85\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78017.7344 - accuracy: 0.0760\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 0.1300\n",
            "t= 86\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 39433.4570 - accuracy: 0.0920\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 0.1240\n",
            "t= 87\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 91096.7266 - accuracy: 0.0900\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 0.1320\n",
            "t= 88\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 323311.2188 - accuracy: 0.0980\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.1360\n",
            "t= 89\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 54275.8555 - accuracy: 0.0660\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.1300\n",
            "t= 90\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20858.5723 - accuracy: 0.0840\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.1280\n",
            "t= 91\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 22817.9121 - accuracy: 0.0860\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.1180\n",
            "t= 92\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9481.7588 - accuracy: 0.0980\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.1260\n",
            "t= 93\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133082.3125 - accuracy: 0.0960\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.1380\n",
            "t= 94\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12808.2725 - accuracy: 0.0920\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.1400\n",
            "t= 95\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 28112.8711 - accuracy: 0.0960\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.1460\n",
            "t= 96\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157471.8438 - accuracy: 0.1100\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.1160\n",
            "t= 97\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 31779.7207 - accuracy: 0.1140\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.1320\n",
            "t= 98\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11869.6641 - accuracy: 0.1040\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.1260\n",
            "t= 99\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81948.1016 - accuracy: 0.0840\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.1260\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.8234 - accuracy: 0.1123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.8233845233917236, 0.11230000108480453]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}